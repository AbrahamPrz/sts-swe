376 parte tres administración de la calidad de seis desviaciones estándar —3.4 casos (defectos) por millón de ocurrencias—, lo que implica un estándar de calidad extremadamente alto. la metodología seis sigma define tres etapas fundamentales: • definir los requerimientos del cliente y los que se le entregan, así como las metas del proyecto a través de métodos bien definidos de comunicación con el cliente. • medir el proceso existente y su resultado para determinar el desempeño actual de la calidad (recabar métricas para los defectos). • analizar las métricas de los defectos y determinar las pocas causas vitales. si se trata de un proceso de software existente que se requiere mejorar, seis sigma sugiere dos etapas adicionales: • mejorar el proceso, eliminando las causas originales de los defectos. • controlar el proceso para asegurar que el trabajo futuro no vuelva a introducir las causas de los defectos. estas etapas fundamentales y adicionales en ocasiones son conocidas como método dmamc (definir, medir, analizar, mejorar y controlar). si una organización va a desarrollar un proceso de software (en vez de mejorar uno exis- tente), a las etapas fundamentales se agregan las siguientes: • diseñar el proceso para 1) evitar las causas originales de los defectos y 2) cumplir los requerimientos del cliente. • verificar que el modelo del proceso en realidad evite los defectos y cumpla los requeri-mientos del cliente. esta variación en ocasiones es denominada método dmadv (definir, medir, analizar, diseñar y verificar). el estudio detallado de seis sigma se deja a fuentes dedicadas a ese tema. si el lector tiene interés al respecto, consulte [isi08], [pyz303] y [sne03]. 16.6 c onfiabilidad del software no hay duda de que la confiabilidad de un programa de cómputo es un elemento importante de su calidad general. si un programa falla repetida y frecuentemente en su desempeño, importa poco si otros factores de la calidad del software son aceptables. la confiabilidad del software, a diferencia de muchos otros factores de la calidad, se mide y estima directamente mediante el uso de datos históricos del desarrollo. la confiabilidad del software se define en términos estadísticos como “la probabilidad que tiene un programa de cómputo de operar sin fallas en un ambiente específico por un tiempo específico” [mus87]. para ilustrar lo anterior, digamos que se estima que el programa x tiene una confiabilidad de 0.999 durante ocho horas de procesamiento continuo. en otras palabras, si el programa x fuera a ejecutarse 1 000 veces y requiriera un total de ocho horas de tiempo de procesamiento continuo (tiempo de procesamiento), es probable que operara correctamente (sin fallas) 999 veces. siempre que se trate de la confiabilidad del software, surge una pregunta crucial: ¿qué signi- fica el término falla? en el contexto de cualquier análisis de la calidad y confiabilidad del soft-ware, la falla significa la falta de conformidad con los requerimientos del software. pero, incluso con esta definición, hay gradaciones. las fallas pueden ser leves o catastróficas. una falla podría corregirse en segundos, mientras que otra tal vez requiera de varias semanas o meses de trabajo para ser corregida. para complicar más el asunto, la corrección de una falla quizá dé como re-sultado la introducción de otros errores que a su vez originen otras fallas.¿cuáles son las etapas fundamentales de la metodología seis sigma?? cita: “el precio inevitable de la con-fiabilidad es la simplicidad.” c. a. r. hoare 16pressman(368-382).indd  37616pressman(368-382).indd  376 14/1/10  17:02:1614/1/10  17:02:16