26-27 esperar a que terminen los dos subprocesos antes de comprobar los resultados. 29 registrar el valor final. 31-32 ¿es diferente endingid a lo que esperábamos? en caso afirmativo, se finaliza la prueba; hemos demostrado que el código es incorrecto. en caso negativo, volver a intentarlo. 35 si hemos llegado hasta aquí, la prueba no ha podido demostrar que el código de producción era incorrecto en una cantidad de tiempo razonable; el código ha fallado. o no es incorrecto o no hemos realizado suficientes iteraciones para que se produzca la condición de fallo. esta prueba establece las condiciones de un problema de actualización concurrente. sin embargo, el problema es tan infrecuente que la mayoría de las veces la prueba no lo detecta. en realidad, para detectar el problema debemos establecer el número de iteraciones en más de un millón. incluso con esa cantidad, en diez ejecuciones de un bucle de 1 000 000, el problema sólo apareció una vez, lo que significa que debemos aumentar las iteraciones para obtener fallos fiables. ¿cuánto estamos dispuestos a esperar? aunque ajustáramos la prueba para obtener fallos fiables en un equipo, seguramente tendríamos que ajustarla con otros valores para ilustrar el fallo en otro equipo, sistema operativo o versión de la mvj. y es un problema sencillo . si no podemos demostrarlo, ¿qué pasará cuando detectemos problemas realmente complejos? ¿qué enfoques debemos adoptar para demostrar este sencillo fallo? y, sobre todo, ¿cómo podemos crear pruebas que demuestren fallos en un código más complejo? ¿cómo podremos saber si el código tiene fallos cuando ni siquiera sabemos dónde buscar? veamos algunas sugerencias: pruebas monte carlo: crear pruebas flexibles que se puedan ajustar. después, ejecutarlas repetidamente, por ejemplo, en un servidor de prueba, y cambiar los valores de ajuste aleatoriamente. si las pruebas 430