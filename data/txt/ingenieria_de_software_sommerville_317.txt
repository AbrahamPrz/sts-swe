300  Capítulo 11 ■ Conﬁ  abilidad y seguridad sistemas de control de procesos en plantas químicas y farmacéuticas, y los sistemas de  control de automotores. El control de hardware de los sistemas críticos para la protección es más fácil de implementar y analizar que el control del software. A pesar de ello, ahora se construyen sistemas de tal complejidad que no pueden controlarse tan sólo con el hardware. El con-trol del software es esencial debido a la necesidad de manejar gran cantidad de sensores y actuadores con leyes de control complejas. Por ejemplo, una aeronave militar avanzada, aerodinámicamente inestable, requiere ajuste continuo, controlado por software, de sus superficies de vuelo para garantizar que no se desplome. El software crítico para la protección se divide en dos clases: 1. Software primario crítico para la protección Éste es software embebido que sirve  como controlador en un sistema. El mal funcionamiento de tal software puede repe-tirse en el hardware, lo cual derivaría en una lesión humana o daño ambiental. El soft-ware de bomba de insulina, que se trató en el capítulo 1, es un ejemplo de un sistema primario crítico para la protección. La falla del sistema puede conducir a una lesión en el usuario. 2. Software secundario crítico para la protección Es un software que podría repercutir  indirectamente en una lesión. Un ejemplo de dicho software consiste en un sistema de diseño de ingeniería auxiliado por computadora, cuyo mal funcionamiento ocasionaría un error de diseño en el objeto por desarrollar. Esta equivocación quizá cauce una lesión a los individuos, si el sistema diseñado funciona mal. Otro ejemplo de un sis-tema secundario crítico para la protección es el sistema de administración de atención a la salud mental, MHC-PMS. La falla de este sistema cuando un paciente inestable no se trata de manera adecuada podría llevar a que éste se lesione a sí mismo o a otros.  La fiabilidad y protección del sistema se relacionan, pero un sistema fiable puede ser inseguro y viceversa. El software todavía suele comportarse de tal forma que el compor-tamiento resultante del sistema conduzca a un accidente. Hay cuatro razones por las que los sistemas de software que son fiables no necesariamente son seguros: 1. Nunca se puede tener una total certeza de que un sistema de software esté libre de  fallas en el desarrollo y sea tolerante a los mismos. Las fallas en el desarrollo no detectadas pueden estar inactivas durante mucho tiempo y las fallas en la operación del software pueden ocurrir después de muchos años de operación infalible. 2. La especificación podría estar incompleta en cuanto a que no describe el compor-tamiento requerido del sistema en algunas situaciones críticas. Un alto porcentaje de mal funcionamiento del sistema (Boehm et al., 1975; Endres, 1975; Lutz, 1993; Nakajo y Kume, 1991) es resultado de errores de especificación más que de diseño. En un estudio de errores en sistemas embebidos, Lutz concluye:  . . . las dificultades con los requerimientos son la clave principal de los  errores de software que se relacionan con la seguridad, los cuales persisten hasta la integración y las pruebas del sistema. 3. El mal funcionamiento del hardware origina que el sistema se comporte de forma impredecible, y presente al software con un entorno no anticipado. Cuando los com-ponentes se hallan cerca de la falla física, éstos pueden comportarse de manera errá-tica y generar señales fuera de los rangos para el manejo del software. M11_SOMMERVILLE_INGENIERIA_1ED_SE_289-308.indd   300M11_SOMMERVILLE_INGENIERIA_1ED_SE_289-308.indd   300 3/18/11   4:54:18 PM3/18/11   4:54:18 PM