12.2 ■ Especificación de protección  317  La figura 12.3 muestra una clasificación de riesgo sobre los peligros identificados en  la sección previa para el sistema de entrega de insulina. Los peligros que se relacionan con el cálculo incorrecto de insulina se separaron en sobredosis y subdosis de insulina. Una sobredosis de insulina es potencialmente más grave que una subdosis de insulina a corto plazo. La sobredosis de insulina podría derivar en disfunción cognitiva, coma y, a final de cuentas, en la muerte. La subdosis de insulina conduce a altos niveles de azúcar en la sangre. A corto plazo, causa fatiga, pero sus consecuencias no son muy graves; sin embargo, a largo plazo, conduciría a severos problemas cardiacos, renales y oculares. Los peligros 4 a 9 en la figura 12.3 no se relacionan con software; sin embargo, éste desempeña un papel en la detección de peligros. El software que monitoriza el hardware debe monitorizar el estado del sistema y advertir acerca de problemas potenciales. Con frecuencia, las advertencias permitirán la detección del peligro antes de que ocurra un accidente. Los ejemplos de peligros que pueden detectarse son la falla de energía, que se descubre al monitorizar la batería, y la ubicación incorrecta de la máquina, que suele detectarse al monitorizar señales del sensor de azúcar en la sangre. Desde luego, el software de monitorización en el sistema se relaciona con la protec-ción. La falla para detectar un peligro podría derivar en un accidente. Si el sistema de monitorización falla, pero el hardware funciona de manera correcta, entonces ésta no es una falla grave. No obstante, si el sistema de monitorización falla y, en consecuencia, la falla del hardware no se detecta, esto tendría consecuencias más drásticas.  12.2.3 Análisis del peligro El análisis del peligro es el proceso que descubre las causas raíz de los peligros en un sistema de protección crítico. Su meta es detectar qué eventos o combinaciones de even-tos causarían una falla de sistema que derive en un peligro. Para hacerlo, se puede usar un enfoque descendente o uno ascendente. Las técnicas deductivas descendentes, que tienden a ser más fáciles de usar, comienzan con el peligro y trabajan con éste hasta la posible falla de sistema. Las técnicas inductivas ascendentes comienzan con una falla de sistema propuesta e identifican qué peligros resultarían por dicha falla. Se han planteado varias técnicas como posibles enfoques para la descomposición o el análisis del peligro, las cuales resume Storey (1996). Incluyen revisiones y listas de veri-ficación, técnicas formales como el análisis de red de Petri (Peterson, 1981), lógica for-mal (Jahanian y Mok, 1986) y análisis de árbol de fallas (Leveson y Stolzy, 1987; Storey, 1996). Como no se tiene espacio para estudiar aquí todas esas técnicas, se examinará un enfoque ampliamente usado para el análisis de peligro basado en árboles de fallas. Esta técnica es bastante sencilla de entender sin un conocimiento especializado del dominio. Para hacer un análisis de árbol de fallas, comience con los peligros identificados. Para cada peligro se puede trabajar entonces en retroceso, con la finalidad de descubrir las posi-bles causas de dicho peligro. Coloque el peligro en la raíz del árbol e identifique los esta-dos del sistema que podrían conducir a tal peligro. Para cada uno de dichos estados, es posible identificar entonces más estados de sistema que conduzcan hacia ellos. Continúe con esta descomposición hasta que llegue a las causas raíz del riesgo. Los peligros que sólo pueden surgir a partir de una combinación de causas raíz son, por lo general, menos probables de conducir a un accidente, que aquellos peligros con una sola causa raíz. La figura 12.4 es un árbol de fallas sobre los peligros relacionados con software en el sistema de entrega de insulina que podrían llevar a administrar una dosis incorrecta de insulina. En este caso, se fusionaron la subdosis de insulina y la sobredosis de insulina M12_SOMMERVILLE_INGENIERIA_1ED_SE_309-340.indd   317M12_SOMMERVILLE_INGENIERIA_1ED_SE_309-340.indd   317 3/18/11   4:55:10 PM3/18/11   4:55:10 PM